# Health-check traffic spike

- Start: 5pm, 22 November 2013
- duration: 1.5 hours
- environment: PROD

## Summary

Increased traffic from the probes sent by the CDN to health-check the backend caused an corresponding increase in load on the Content API, rendering it unstable for
a short period of time. Removing the health-check traffic allowed the backend to recover and the stack to get itself back in to a healthy state.

## Resolution (shoet-term)

We tailed the production nginx and article server logs and identified two URLs that were being hit several thousand times a minute.

These were identified as our health-check URLs.

We temporarily intercepted these two requests in nginx (remember folks, you can patch nginx in production very quickly), which had the effect of
reducing load on the Content API.

```
# nginx instruction to bounce a http 200 back at the client
location ~ ^/football/2010/jul/11/rafa-benitez-yossi-benayoun-liverpool$ {
    default_type text/html;
    return 200;
}
```

The Content API did not recover, so we switched back to CAPI v1 for five minutes, which allowed the v2 API to stabilse, after which we moved back to v2. 

## Resolution (long-term)

_TODO Once we have a diagnosis._

## User-facing consequences

An approximate 30% drop in traffic was observed on the Ophan dashboards throughout the duration of the incident.

## Thoughts

- There is little protection (caching etc.) between ourselves and the Content API.
- Our build processes depends on a healthy production stack to pass the tests and produce the artefact. During times of instability it is therefore hard to patch the software in the usual way.
- The CloudWatch graphs remained useful throughout the issue. Yesteryear the Ganglia data would often disappear during the outage.
- Likewise the dashboards reflected the state of the stack well.

## Actions

- We need to isolate the CDN health-check from the stack.
- ...

